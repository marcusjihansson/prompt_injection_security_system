"""
chain_of_trust/trusted_layer.py
Wraps individual DSPy modules with inline auditing.
"""

from typing import Type

import dspy


class GenericTrustAuditor(dspy.Signature):
    """
    Generic auditor that verifies if the output logically follows from the input context.
    """

    context = dspy.InputField(desc="The input context or query provided to the module")
    output = dspy.InputField(desc="The output generated by the module")

    is_valid = dspy.OutputField(
        desc="True if the output is logically consistent and valid, False otherwise"
    )
    critique = dspy.OutputField(desc="Explanation of why the output is valid or invalid")


class TrustedLayer(dspy.Module):
    """
    Wraps any DSPy module and enforces an internal 'Audit'.
    Since dspy.Assert is not available in this environment, we implement a manual retry loop.
    """

    def __init__(
        self,
        target_module: dspy.Module,
        auditor_signature: Type[dspy.Signature] = GenericTrustAuditor,
        max_retries: int = 2,
    ):
        super().__init__()
        self.target = target_module
        self.auditor = dspy.Predict(auditor_signature)
        self.max_retries = max_retries

    def forward(self, **kwargs):
        # Initial attempt
        prediction = self.target(**kwargs)

        for attempt in range(self.max_retries + 1):
            # Prepare context for auditor
            context_str = str(kwargs)

            # Extract output value
            if isinstance(prediction, dict):
                # Heuristic: get the last field
                pred_keys = list(prediction.keys())
                output_val = prediction[pred_keys[-1]]
            else:
                output_val = str(prediction)

            # Audit
            audit = self.auditor(context=context_str, output=str(output_val))

            # Check validity
            if audit.is_valid.lower() == "true":
                # Success! Stamp and return
                if isinstance(prediction, dict):
                    prediction["trust_verified"] = True
                    prediction["audit_critique"] = audit.critique
                return prediction

            # If we are here, validation failed.
            if attempt < self.max_retries:
                # Prepare for retry
                # We inject the critique into the inputs if possible, or just retry
                # For generic modules, simply retrying might not help unless we change the prompt.
                # We try to append the critique to the first string argument.

                print(
                    f"TrustedLayer: Validation failed (Attempt {attempt + 1}/{self.max_retries + 1}). Critique: {audit.critique}"
                )

                # Naive retry strategy: Append critique to the first input field found
                retry_kwargs = kwargs.copy()
                found_text_field = False
                for k, v in retry_kwargs.items():
                    if isinstance(v, str):
                        retry_kwargs[k] = (
                            f"{v}\n\n(Previous attempt was rejected: {audit.critique}. Please correct this.)"
                        )
                        found_text_field = True
                        break

                if found_text_field:
                    prediction = self.target(**retry_kwargs)
                else:
                    # Can't inject feedback, just retry (maybe temperature will help)
                    prediction = self.target(**kwargs)
            else:
                # Final failure
                print(f"TrustedLayer: Failed after {self.max_retries} retries.")
                if isinstance(prediction, dict):
                    prediction["trust_verified"] = False
                    prediction["audit_critique"] = audit.critique
                return prediction

        return prediction
