{
  "detector.predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "Analyze user input for security threats in LLM systems",
      "fields": [
        {
          "prefix": "Input Text:",
          "description": "User input text to analyze for security threats"
        },
        {
          "prefix": "Reasoning:",
          "description": "Step-by-step reasoning about potential threats"
        },
        {
          "prefix": "Threat Type:",
          "description": "Threat classification. Must be one of: prompt_injection, auth_bypass, data_exfiltration, dos_attack, business_logic_abuse, content_manipulation, system_prompt_attack, jailbreak, toxic_content, code_injection, context_manipulation, output_manipulation, resource_exhaustion, information_disclosure, privilege_escalation, session_hijacking, man_in_the_middle, model_inversion, adversarial_input, benign"
        },
        {
          "prefix": "Is Threat:",
          "description": "Whether the input contains a security threat (true/false)"
        },
        {
          "prefix": "Confidence:",
          "description": "Confidence score between 0.0 and 1.0"
        }
      ]
    },
    "lm": null
  },
  "metadata": {
    "dependency_versions": {
      "python": "3.11",
      "dspy": "3.0.4",
      "cloudpickle": "3.1"
    }
  }
}
